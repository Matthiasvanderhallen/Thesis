\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{todonotes}
\usepackage{hyperref}
\usepackage{listings}
\usepackage[style=mla,babel=hyphen,backend=biber]{biblatex}

\input{./tex/cmds}

\begin{document}
%\newcommand{\emphref}[1]{\emph{}}
\newcommand{\lsttext}[1]{\lstinline{#1}}
\newcommand{\surroundrule}[2][0.3em]{
\leavevmode\raisedrule[#1]{1pt}#2\raisedrule[#1]{1pt}}

\newenvironment{attack}[1]{\par\par\noindent\hspace{-1ex}\surroundrule{#1}\vspace{-0.5em}\par\par}{\vspace{0.5em}\par\par\noindent\leavevmode\raisedrule[1em]{1pt}\\}
%\begin{flushleft}


\hypersetup{colorlinks=false, pdfborder={0 0 0}}

\chapter{A Compilation Example\label{chap:ACompilationExample}}

This chapter firstly describes the \mbox{MiniML} source language (\myref{sec}{sec:MiniML}), a subset of the ML language whose syntax and semantics are reminiscent of those of Standard ML.
\myref{sec}{sec:MLExample} then introduces an example program that will be used to show the secure compilation scheme. This chapter continues by describing the LLVM intermediate language to which the first translation occurs (\myref{sec}{sec:LLVM}). This chapter concludes by translating the earlier proposed example program, showing the resulting LLVM code.
%The secure compilation scheme is shown from an example program written in the source language, \mbox{MiniML}, which is a subset of the ML language. Its syntax and semantics are reminiscent of those used in Standard ML.

\section{MiniML\label{sec:MiniML}}
The ML language is a functional programming language which is well known for its module system. This module system aims to group data and code together into coherent entities, called the modules.

A \emph{structure} is the most basic type of module. It can be defined using the \texttt{struct...end} construct and provides a set of bindings for types, values and functions. A structure specifies a name for the binding and the corresponding value, called \emph{implementation}. Structures provide the possibility of grouping related code and data, fulfilling the need of \emph{encapsulation} in software. However, the need for \emph{data abstraction} is not yet fulfilled. \myref{lst}{code:DictionaryStructureExample} shows how a dictionary of strings to strings might be implemented by a module.
~
\begin{lstlisting}[frame=single, language=ML,caption=An example structure showing the definition of a dictionary in ML, label=code:DictionaryStructureExample,numbers=left]
structure Dictionary = struct
   type dictionary = (string, string) list
   val emptyDictionary = []
   fun insert(x, y, d) = (x,y)::d
end 
\end{lstlisting}

\myref{lst}{code:DictionaryStructureExample} firstly defines a type dictionary, which is defined to be a type synonym for a list of string pairs, a value representing the empty dictionary (\texttt{emptyDictionary}) and a function for inserting data into the dictionary (\texttt{insert}).

As it stands, the dictionary type is a type synonym for lists of string pairs, and any such list could be used where a dictionary is expected. However, the concept of a dictionary does not require users to know that the dictionary type is implemented as a list of string pairs. According to the principle of data abstraction, it is favourable to hide this information from the user of the dictionary module.

Here the idea of a signature comes into play. A signature groups a set of types, values and functions without providing an implementation. It provides a way of abstracting over structures that implement the same logical concept using a different implementation. A possible signature for dictionaries is shown in \myref{lst}{code:SignatureDictionaryExample}.
~
\begin{lstlisting}[frame=single, language=ML, caption=An example signature showing the declaration of a dictionary in ML, label=code:SignatureDictionaryExample, numbers=left]
signature DICTIONARYSIGNATURE = sig
   type dictionary
   val emptyDictionary : dictionary
   val insert: string -> string -> dictionary
end
\end{lstlisting}

A signature guarantees that two implementations of the same logical concepts are interchangeable for each other by standardizing the way an implementation communicates with the other code. It can also abstract the fact that the current implementation for dictionaries uses lists, as well as obscuring any helper methods that the specific implementation defines in order to simplify its internal workings. This last functionality of a signature is a way to perform \emph{information hiding}.

%In order to simplify this study, the ML language is simplified to its core, resulting in the smaller \mbox{MiniML} language. This will, at first, only feature modules. Later on, It will be extended with more advanced concepts of ML, such as functors.

The \mbox{MiniML} fragment discussed here was chosen to encorporate the idea of modules, more complex language features will be added later.

\section{A Cipher In ML\label{sec:MLExample}}
\myref{lst}{code:Example} presents an example program that consists of the definition of a signature that represents symmetric cyphers, a concept used in cryptography. This example was chosen since the modules related to cryptography are usually under more scrutiny with regards to the privacy of their internal values.
The code in \myref{lst}{code:Example} defines a signature \texttt{SYMMETRICCIPHER}. This signature describes the common traits between modules that implement a symmetric cipher.
In order to implement a symmetric cipher, one must have a credential, i.e. the key, and two functions, \texttt{encrypt} and \texttt{decrypt}, which take data and credentials.
The \texttt{encrypt} function takes the raw data and encodes it in a way only those with knowledge of the correct credentials can later use the \texttt{decrypt} function to transform the encoded data back into the raw data.

\begin{lstlisting}[frame=single, language=ML,numbers=left, label=code:Example, caption=Example of a security sensitive module specifying and implementing a symmetric cypher.]
signature SYMMETRICCIPHER = sig 
    type cred
    val newcredentials : cred
    val encrypt: int -> cred -> int
    val decrypt: int -> cred -> int
end

structure Caesar :> SYMMETRICCIPHER = struct
    type cred = int
    fun newcredentials = rand
    fun encrypt(a,cred) = (a + cred)%26
    fun decrypt(a, cred) = (a - cred)%26
    val seed = 3
    fun rand = time.now * seed
end
\end{lstlisting}

From line 8 of \myref{lst}{code:Example} onwards the definition of a structure called \texttt{Caesar} is given. \texttt{Caesar} implements the \texttt{SYMMETRICCYPHER} signature.
In this context, \texttt{Caesar} provides the \texttt{newcredential}, \texttt{encrypt} and \texttt{decrypt} functions. For internal use it also possesses the necessary characteristics of a pseudorandom number generator, namely a seed value and a rand function that provides a pseudorandom number. It is necessary to hide the seed value from users since this would allow attackers to predict the output of the pseudorandom number generator.

The \texttt{Caesar} structure is forced to conform to the signature \texttt{SYMMETRICCIPHER} by means of \emph{opaque ascription (\texttt{:>})}. This not only forces the module to implement all the necessary elements of the signature, but it also restricts the means of interaction with the module to those elements that are explicitly mentioned in the interface. It is this notion of \emph{opaque ascription} that dictates what it means for this module to be secure. Concretely, to be secure, this module hides its \texttt{rand} function and its seed value from any outside code, only allowing the code internal to the structure to access this value or call the function.

%This example can later be broadened so that the \texttt{Caesar} structure becomes a functor that is parameterized to use an external module as its PRNG.

\section{LLVM Intermediate Representation \label{sec:LLVM}}
This section introduces the LLVM intermediate representation. It also specifies the expected LLVM intermediate representation code for the example in \myref{lst}{code:Example}.

\subsection{LLVM}
LLVM, short for \emph{Low Level Virtual Machine} is the name of a project providing many different and closely affiliated utilities concerned with the compilation process. One of the important utilities being used in this work is LLVMs intermediate representation. This intermediate representation is defined in an attempt towards providing a shared abstraction that the compilers of many languages can use. 
From this point on, any form of optimization can be done on the LLVM intermediate representation, and thus might be shared between the different high-level languages.

When all required optimizations are performed, one can compile the intermediate language into machine code and perform linking of all necessary code. Any special modification necessary to run on specific target platforms can be shared as well. In order to focus on the security of the compilation, the more aggressive optimization capabilities of LLVM will not be used.
\\[1em]
The secure compiler for \mbox{MiniML} will translate \mbox{MiniML} code into this intermediate representation.
It is possible to write a program in this LLVMs intermediate representation (LLVM IR) using one of three different and equivalent encodings:
\begin{itemize}
\item A bitcode format
\item Textual assembly language
\item A symbolic representation
\end{itemize}

This thesis will use the textual assembly language as representation for LLVM IR programs, because this makes examples and results more understandable and human readable.
While it is possible to generate LLVM IR programs using the LLVM API, this work chooses to generate the human readable intermediate code itself, because it offers more direct control over the resulting translation.

The benefit of LLVMs intermediate representation is not limited to the points mentioned above. The LLVM intermediate representation works at a higher level of abstraction than standard assembly does. Two important additional aspects make the intermediate representation used by LLVM of a higher level of abstraction than standard assembly code:

\begin{description}
\item[Type System] More information about the program is captured by LLVM than when using regular assembly, using LLVMs type system
\item[SSA] For optimization purposes, the LLVM IR adheres to the \emph{static single assigment} paradigm, or \emph{SSA}. This implies that every register can be assigned a value only once. However, this restriction poses no real hindrance to a functional language as \mbox{MiniML}
\item[Register Limitations]  The LLVM intermediate representation abstracts away the fact that real architectures have only a given amount of registers. Instead, one can write a program assuming an infinite amount of registers. This results in many more variables in use than available registers.
In a later compilation stage this consequence is remedied using the technique of \emph{spilling}. Variable spilling occurs by mapping the variables in use to the smaller set of available registers, saving all variables that could not be assigned to a register in RAM memory in the stack.\todo{This is important for the secure compilation (clearing registers after function calls end). It might be necessary to rework this subsection to stress this more.}
\end{description}

\subsection{Translating MiniML concepts to LLVM}
Compiling from \mbox{MiniML} to LLVM IR means the high level abstractions made in \mbox{MiniML}, for example \emph{signatures} and \emph{structures}, must be mapped to lower level constructs that are available in the LLVM intermediate representation. This section presents these different mappings.

\begin{description}
\item[Structures]
LLVM already provides the concept of a module as a separate unit of compilation. This means each LLVM module is compiled to a single different object file. Firstly, an LLVM module declares which external functions will be provided by other code, and then continues by defining and implementing its own code and data. These definitions and external references are compiled into a single object file. LLVM poses no restrictions on the access of data and functions within a single module, but in order to manage the access of data and functions from within other modules, the object file to which a module is compiled is accompanied by a link table specifying which methods are defined and made externally visible, which is used to match the declaration of external functions with their implementation in other object files. The link tables represent what other code knows about the definitions contained within the compiled module.

%This means that LLVM already provides a way of performing code and data encapsulation.

%  When compiling these modules the result is a single object file. Each of these object files is accompanied by a.

The functionality offered by LLVM IR modules makes them the right target  to map the different ML structures onto.

\item[Functions]
LLVM provides the concept of a function as a set of basic blocks of code. 
These LLVM IR functions allow us to modify the visibility of a function using the linkage keyword. 
%The concept of a function as a basic building blocks allows us to specify the visibility of these blocks towards outside code. 

When linking the object files that result from the compilation of different modules, LLVM looks for the implementation of externally declared functions in the different object files, keeping into account whether or not the code was in fact declared to be visible outside the module. It is possible to map ML functions directly to their LLVM counterpart.

\item[Signatures]
While structures can be mapped directly onto the concept of a module in LLVM, the information provided in signatures will mainly affect metadata in the resulting code or influence the specific implementation of different elements inside the modules.

When a structure is opaquely ascribed, or \emph{sealed} by a signature, we must make sure that the values and functions defined in the structure but not specified in the signature are not externally visible. The first step in protecting these internal functions consists of marking these members as private in the module corresponding to the ML structure. This will filter these members from the object files link table. %This way these private members are protected from access by any of the external code generated by the same compiler.

%Structures will be mapped onto the different modules, while the information provided in the signatures will mainly affect metadata in the resulting code, or influence the specific implementation of different elements inside the modules.

\item[Fields]
Translations of the fields happens as global constants within a module. Since their value is unchanging, the \emph{SSA} paradigm poses no real limitation.

\end{description}

\section{Translation Example: The Caesar Cipher}
In order to study the compilation scheme, the example ML code in \myref{lst}{code:Example} is translated to LLVM IR. The translation to LLVM intermediate representation is given in code in \myref{lst}{llvm:Example}

\begin{lstlisting}[frame=single,numbers=left, language={[x86masm]Assembler}, caption=LLVM IR for the example,
label=llvm:Example]
define i32 @newcredentials(){
	%0 = call i32 @newcredentials_internal()
	ret i32 %0
}

define private i32 @newcredentials_internal(){
	%0 = call i32 @rand()
	ret i32 %0
}

define i32 @encrypt(i32, i32) {
	%2 = call @encrypt_internal(%0, %1)
	ret i32 %2
}

define private i32 @encrypt_internal(i32, i32) { 
entry:
	%x = add i32 %0, %1
	%y = urem i32 26, %x 
	ret i32 %y
}

define i32 @decrypt(i32, i32) { 
	%2 = call @decrypt_internal(%0, %1)
	ret i32 %2
}

define private i32 @decrypt_internal(i32, i32) { 
entry:
	%x = sub i32 %0, %1
	%y = urem i32 26, %x 
	ret i32 %y
}

@.seed = private constant i32 3	

define private i32 @rand() {
entry:
	%t = load i32* @.seed
	ret i32 %t
}
\end{lstlisting}

This code, that implicitly is part of a module, consists of a list of \emph{global values}, denoted by the @ sign.
Every value, be it a global function or a global variable, has a \emph{linkage} type associated with it.
Linkage types control the accessibility of of variables and functions. The two linkage types in use are \texttt{private}, which makes a value only accessible by objects inside the same module, and the default linkage type, \texttt{external}.

The code in \myref{lst}{llvm:Example} specifies 5 different global values, corresponding to the 5 definitions in the \texttt{Caesar} structure:
\begin{description}
\item[newcredentials] The first translated function is the \texttt{newcredentials} function.
On lines 1-4 in the code of \myref{lst}{llvm:Example}, a proxy for the function is defined and its return type is declared to be i32, i.e. an integer. Since no linkage type is explictly specified, linkage type `external'  is used.

This proxy acts as a wrapper around the real translation of \texttt{newcredentials} that can be seen on lines 6-9. This proxy is the entry point to the function that is made available to the untrusted code. This proxy can perform the security precautions that have to be taken when taking values from or returning values to the untrusted code.

The body of the internal function \texttt{newcredentials\_internal} implements the functionality of the ML \texttt{newcredentials} function.
\texttt{newcredentials\_internal} performs a call to the rand function, saving the resulting return value. It does so in a temporary local variable called \%0. This is returned using the \emph{ret} assembly function.

\item[encrypt \& decrypt] Next are the \texttt{encrypt} en \texttt{decrypt} functions. The translation starts with the definition on line 11 in the code of \myref{lst}{llvm:Example}. Again, as these functions are available in ML for untrusted code, proxies are provided as entry points where security precautions can be made. These can be found on lines 11-14 and 23-26. The internal functions can be found on lines 16-21 and 28-33.

The definition of these proxies as well as the internal functions specify the return type, as well as the different argument types. Since these are all of type `integer', the type i32 is being used.

The body of the internal function uses the arguments in two calls to arithmetical assembly functions and returns the result.
\item[seed] The variable \texttt{seed} is translated to a global variable. As the structure is opaquely ascribed by the signature \texttt{SYMMETRICCIPHER}, and the variable \texttt{seed} is not specified in this signature, it should be hidden from any outside components.

To help achieve this protection and mark this information, the linkage type is specified to be \emph{private}.

The definition of \texttt{seed} can be seen on line 35 in the code of listing~\myref{lst}{llvm:Example}
\item[rand] The function \texttt{rand} is defined starting line 23 and onwards in \myref{lst}{llvm:Example}. For the same reasons as the variable \texttt{seed}, its linkage type is set to private. It also follows that no proxy is necessary for the \texttt{rand} function.

In its body, it returns the value of the seed. Since all global values are pointers, the pointer must be dereferenced using a load operation, saving the value to a local variable. This value is then returned.
\end{description}

\subsection{MiniML-specific security concerns}

\subsubsection{Register Clearing}
Any communication in \mbox{MiniML} normally only occurs through information passed along by returns and method calls.
In the case of low level architecture however, all communication occurs through the unprotected memory, through flags and through the CPU registers.  This means that a low level attacker can try to perform side channel communication.

In order to prevent the leaking of protected data through side channels, it is important to ensure that the information passed through unprotected memory, flags and registers is restricted to that information being passed by the returns and method calls in \mbox{MiniML}.
Thus, any callback or return to untrusted code must:
\begin{itemize}
\item Clear the flags
\item Clear the registers, except those being used to pass a parameter or a return value.
\end{itemize}


If these registers and flags, which were possibly modified by the protected code, are not reset when returning execution to unprotected memory, code running in the unprotected memory will be able to read the values in these registers and flags, breaking confidentiality. The code could even modify these values, resulting in a modification of control flow if execution is later returned to the protected code while expecting these values to be uncorrupted.

However, since the LLVM intermediate representation does not allow multiple assignments to the same registers, it is impossible to clear a register simply by overwriting its value.
Furthermore, the LLVM IR does not know how many registers it can use, instead assuming an infinite amount of registers, as mentioned earlier. This means that clearing these registers must happen later on in the compilation process, introducing an extra LLVM pass.

\subsubsection{Opaque types}

The \mbox{MiniML} language allows a programmer to define ones own types using the type keyword. Taking another look at the Dictionary example of \myref{lst}{code:DictionaryStructureExample}, this happens for example on line 2. The modules internal representation of a dictionary is a list of string pairs, but clearly this is some internal choice that the programmer does not want to make explicit, which is why the type synonym 'dictionary' is kept opaque, as can be seen in \myref{lst}{code:SignatureDictionaryExample}, line 2, where the external specification of a type is not revealed to be a list of string pairs.

This is a means of information hiding, if someone were to later rewrite this dictionary structure in such a way that its internal representation becomes a pair of string lists, as in Figure , this would be a perfectly valid change. This change should not result in any changes to the external code, since the specific implementation choice for the dictionary type was not made explicit.

\begin{figure}[!htb]
\begin{lstlisting}[frame=single, language=ML]
structure Dictionary = struct
   type dictionary = (string list, string list)
   val emptyDictionary = []
   fun insert(x, y, (fst,snd)) = (x::fst, y::snd)
end
\end{lstlisting}
\label{code:DictionaryStructureExample2}
\caption{An alternative structure defining a dictionary.}
\end{figure}

Even more so, one would expect the two programs/modules to be contextually equivalent! However, clearly, if no checking is performed on functions expecting something of type dictionary, a low level attacker could discriminate between the two using the following tactic: call a function expecting a dictionary argument with a self-created list of string pairs. If it gives the expected results, the dictionary implementation being used is the one given in \myref{lst}{code:DictionaryStructureExample}. If not, it is the module described in \myref{lst}{code:DictionaryStructureExample2}, expecting a pair of string lists. This breaks contextual equivalence.

The code must assure that any object, passing as an argument of type dictionary, was in fact created by the module code itself (using the emptydictionary method). If not, it should raise an error (even if the object has the correct type according to the synonyms) in order to prevent an attack on centextual equivalence in the same spirit as the one described above.

This restriction can be enforced if the code creating a dictionary never returns a pointer to this dictionary itself, instead saving this dictionary in an internal list in protected memory. The index in this list can then be returned and used as a mask for the real object. Any function in the module that expects a dictionary as its argument then no longer gets a pointer to this dictionary object in memory, but instead gets the index of the needed dictionary in the internal list.

\todo{The explanation of why extra type information might prove necessary. However: The argument must be presented in a more careful manner. Furthermore, this also depends on whether a separate list is being used per type or not. If a separate list is being used anyway, instead of a central list of masked objects, then the extra type information proves unnecessary, or rather, it is already implicitly available.}

\section{Lessons learnt}

This chapter gave an introduction to the \mbox{MiniML} language, which was chosen because of its special module system and how it specifies security aspects. Formalizing the \mbox{MiniML} language semantics will be the topic of \label{chapter:formalspecification}.

Furthermore, LLVM and its intermediate representation was introduced as the target language.

The chapter proceeded by describing the compilation scheme, showing how \emph{structures} can be mapped to LLVM \emph{modules}, followed by a translation of its \emph{fields} and \emph{functions} to global variables and LLVM \emph{functions}.

\emph{Signatures} were shown to have no translation to a single LLVM concept, instead having an influence on the translation of the modules that it \emph{seals} in linkage types and more subtle ways.

The chapter concluded with a discussion about preventing side channel communication, which makes it necessary to clear registers and flags when calling or returning to any external code.

The existence of opaque types in \mbox{MiniML} means that objects of these opaque types can only be created by methods inside the module that declares the type synonym. To ensure this, the use of masking and the tracking of type information proved necessary.

\chapter{Formal Specification \label{chapter:formalspecification}}
In this chapter the source language, \mbox{MiniML}, and the target language, LLVM IR, will be formally specified. 

First the syntax of \mbox{MiniML} within which a program can be defined will be introduced. Next, the typing rules that a correct program must adhere to is shown. Lastly, the operational semantics govern what a correct program must do once it runs.
\section{MiniML}
\subsection{Syntax}
\newcommand{\longspace}{\;\;\;\;\;\;}
\newcommand{\inlinecode}{\texttt}
First we introduce the syntax of a \mbox{MiniML} program, as seen in \myref{fig}{fig:Syntax}. A program consists of a set of module expressions, denoted as $\overline{\mathit{Mod}}$ using the bar notation for lists\footnote{The bar notation uses $\emptyset$ as the empty set and , as the prepend operator. For example:$\overline{\mathit{Mod}}$ can be the empty set, $\emptyset$, or $\lbrace \Delta, \overline{\mathit{d}}\rbrace^{name}, \overline{Mod}$}. It is then concluded by a single naked value expression, functioning as the main entry point of the program.
This description of a program allows us to first specify a set of signatures as well as a set of module and functors conforming to those signatures.
\\[2ex]
A signature $\Sigma$ is a module type and is represented by a list of \emph{declarations}. A declaration $\Delta$ specifies the type of an value identifier or the signature of a module identifier.
%\\[2ex] 
%A module can be seen as a special case of functors. A module specifies a signature and module body and is uniquely identified with an identifier $M_{i}$. The module body is represented as a list of definitions $\overline{d}$. A module $M_{i}$ with body $\overline{d}$ conforms to a signature $S_{i}$ if every identifier in $S_{i}$ has a definition in the module body, and its typing does not violate the one specified in the signature.
%\\[2ex]
%Functors $F_{i}$, presented as a generalization of modules, specify \todo{Is it always possible to specify the interface of a module? In our simple system, yes, There can be no problem with opaque types since we don't support them.} their own signature, $S_{i}$, as well as a set of signatures upon which it depends, $\overline{S_{n}}$. It then specifies a functor body in which those modules can be used. The functor can be given a set of modules that conform to the dependent signatures. We say the functor is applied to a set of modules. The result of this application behaves as a module that conforms to the interface $S_{i}$ that the functor specified for itself.

\begin{figure}[!htb]
\begin{align*}
\begin{aligned}
\text{Program} ::= \; & \overline{\mathit{Mod}};\;e\\
\\
\text{Value Expression }e \; ::= \; &\mathit{num \; n \;} % | \; \mathit{false} \; | \; \mathit{true} \\
&|\;\mathit{id}  \\
&|\;\mathit{path.id} \\
&|\;e_{1}e_{2} \\
% &|\;(e_{1},e_{2}) \\
&|\;\lambda(p:\tau)\;.\;e \\
&|\;\mathit{let }\; p \; = \; e_{1} \; in \; e_{2} \\
% &|\;\mathit{letrec} \; p \; = \; e_{1} \; in \; e_{2} \\
%&|\; \mathit{if(e_{1}) \; then \; e_{2} \; else \; e_{3}}\\
% &|\;\mathit{p.left}\; | \; \mathit{p.right} \\
% &|\;\mathit{fix\;e} \\
\\
\text{Identifiers } ::= \; & \; id \\ 
&|\;M_{i}\\
% &|\;F_{i}\\
&|\;S_{i}\\
\\
\text{Access Path } \mathit{path} \; ::= \; &\mathit{M_{i}}\\
% &|\;F_{i}(\overline{\mathit{M_{i}}})\\
%&|\;\mathit{this}\\
\\
\text{Mod Expr } \mathit{me} ::= \; & \mathit{sig} \; S_{i} = \Sigma\\
&|\; \mathit{mod} \;  M_{i} : S_{i} = \overline{\mathit{d}} \\
% &|\; \mathit{funct} \; F_{i} (\overline{M_{n}:S_{n}}):S_{i} = \overline{d}\\
\\
\end{aligned}
\begin{aligned}
\text{Mod Types } \mathit{Mod} ::=\;&\lbrace \Sigma, \overline{\mathit{d}} \rbrace^{M_{i}} \\
% &|\; \lbrace \Sigma, \overline{\Sigma}, \overline{d} \rbrace^{F_{i}} \\
\\
\text{Signature } \Sigma \; ::=\; & \overline{\Delta}\\
\\
\text{Declaration } \Delta \; ::=\; & (\mathit{id}:\tau)\\
& | \; (\mathit{M_{i}}:S_{i})\\
\\
\text{Definition } d \; ::= \; &(\mathit{id}=e:\tau)\\
& | \; (\mathit{M_{i}} = \overline{d} : S_{i}) \\
\\
\text{Type }\tau \; ::= \; &nat \\
% &| \; \mathit{bool} \\
&| \; \tau_{1} \rightarrow \tau_{2} \\
% &| \; \tau_{1} \times \tau_{2} \\
% &| \; \alpha\\
\\
\text{Pattern }p \; ::= \; & \mathit{id} \\
&| \; (p,p)\\
\\
\\
\end{aligned}
\end{align*}
\caption{The syntax of MiniML}
\label{fig:Syntax}
\end{figure}

%\subsubsection{Syntax example}
%We now give an example of a syntactically correct \mbox{MiniML} program.

%\begin{figure}[!htbp]
%\begin{verbatim}
%test
%\end{verbatim}
%\caption{Syntax example}
%\label{code:SyntaxExample}
%\end{figure}

\subsection{Type system}
Having defined the syntax for \mbox{MiniML}, we are now able to formalize its type system.

\subsubsection{Type-schemes and contexts}
First, we introduce the concept of a type-scheme, as seen in \myref{fig}{fig:Type-schemesAndContexts}. A type-scheme, sometimes called polytype, introduces polymorphism by making use of the type variable $\alpha$ in the definition of $\tau$, and quantifying it with the universal quantifier $\forall$. This allows any concrete types $\tau$ to 'match' to the type variable. For example, the identity function \inlinecode{id} is typed $id:\forall \alpha. \alpha \rightarrow \alpha$, thereby introducing parametrized polymorphism which enables one to use the same \inlinecode{id} function everywhere regardless of the arguments type.

This concept of a type-scheme will later be used to provide %\todo{explain further}
let-polymorphism.  Note that the definition of a Type-Scheme assures that the resulting type-scheme is in \emph{prenex normal form}, i.e. a string of quantifiers concluded by a quantifier-free ending.
\\[2ex]
Our type system will also need to keep track of the type assumptions and the module, functor and signature definitions. This represents the notion of a \emph{context}. It is in this context that typing will happen. While type checking, the context is what the type checker uses to keep track of the facts it already knows.
\\[2ex]
To access mappings from these contexts, we will introduce projections. For example $\Gamma[M_{i}].\overline{d}$ will look up the mapping $(M_{i} \mapsto \lbrace S,\overline{d}\rbrace)$ in $\Gamma$ and project this to the $\overline{d}$ specified in the mapping. A lookup will \emph{fail} if the identifier has no mapping in the context.

\begin{figure}[!htb]
\begin{align*}
\begin{aligned}
\text{Context }\Gamma ::=\; &\emptyset \\
&| \; (x:\sigma),\Gamma \\
&| \; (M_{i} \mapsto \lbrace \Sigma,\overline{d}\rbrace), \Gamma \\
% &| \; (F_{i} \mapsto \lbrace \Sigma, \overline{\Sigma_{n}}, \overline{d} \rbrace), \Gamma \\
&| \; (S_{i} \mapsto \Sigma), \Gamma
\end{aligned}
\begin{aligned}
\longspace
\end{aligned}
\begin{aligned}
\text{Type-Scheme } \sigma \; ::= \; &\tau \\
&| \; \forall \alpha . \sigma \\
\\
\\
\end{aligned}
\end{align*}
\caption{Type-schemes and contexts in the MiniML type system.}
\label{fig:Type-schemesAndContexts}
\end{figure}

We are now in a position to define a few helpful relations between type-schemes, types and contexts: type-scheme specialization and type-scheme generalization.

\subsubsection{Type-scheme specialization}
The specialization relation $\sigma_{1} \geq \sigma_{2}$ expresses that $\sigma_{2}$ is more specialised than $\sigma_{1}$. This means that the following rule holds:
% $\sigma_{2}$ can be expressed as $\forall \beta_{i}...\beta_{m}.\sigma_{2}'$ and $\sigma_{1}$ as $\forall \alpha_{1}...\forall \alpha_{n}.\sigma_{1}'$, $\sigma_{2}$ is more specialised than $\sigma_{1}$ iff $\sigma_{2}'=[\alpha_{i} \mapsto \sigma_{i}]\sigma_{1}'$ and $\beta_{i} \in free(\sigma_{1})$. In other words, 
%

\[
\tag{specialization}
\frac{\tau_{2}=[\alpha_{i} \mapsto \tau_{i}]\tau_{1} \longspace \beta_{i} \not\in\mathit{free(\alpha_{1}...\forall \alpha_{n}.\tau_{1})}}
{\forall\alpha_{1}...\forall\alpha_{n}.\tau_{1}\geq \forall \beta_{i}...\forall \beta_{m}\tau_{2}'}
\]

In other words, the quantifier-free ending of the more specialized type-scheme can be obtained by consistently replacing all quantified type variables $\alpha_{i}$ in the more general type-scheme by a type $\tau_{i}$, which can possibly contain type variables itself, resulting in the quantifier-free ending of the more specialized type scheme. Furthermore, only variables that were not free in the more general type-scheme can be bound in the specialized type-scheme.

The first condition gives one the possibility to specify the type of a type variable. This second condition forbids one to \emph{rescope} a type variable in the process.

\subsubsection{Type-scheme generalization}
Type-scheme generalisation is the opposite process of type-scheme specialization. However, whereas specialization can be expressed independent of the context, whether or not one is allowed to generalize, is dependent on the context. Generalisation allows one to quantify an unquantified variable, as long as it does not appear unquantified in any type expression in the current context.

\[
\tag{generalization}
\frac{\Gamma \vdash e:\Sigma \longspace \alpha \not\in \mathit{free(\Gamma)}}{\Gamma \vdash e : \forall \alpha . \sigma}
\]


\subsubsection{Typing judgements}
To type check our program, the type checker will perform typing judgements. These typing judgements, which can bee seen in \myref{fig}{fig:TypingJudgements}, are relations between the context and parts of the syntax. They convey the meaning that an expression or other part of the syntax is well-typed in the context $\Gamma$. The typing of a module body and its definitions generates a new typing context $\Gamma'$ for the module. In this resulting context, the declarations must be well-typed.

The $\Gamma \vdash \Diamond$ judgement is a statement of well-formedness of a context $\Gamma$. A context is well-formed if the keyset of the lookup table it represents conforms to the standard notion of a set, meaning every key is used only once.

\begin{figure}[!htb]
\begin{align*}
\text{ExpressionTyping } ::=\;&\Gamma \vdash e: \sigma \\
\text{ModuleTyping } ::= \; &\Gamma \vdash \mathit{Mod} \\
\text{DefinitionTyping } ::= \; &\Gamma \vdash d \rightarrow \Gamma' \\
\text{DeclarationTyping } ::= \;&\Gamma \vdash \Delta \\
\text{Well-formedness } ::=\;&\Gamma \vdash \Diamond
\end{align*}
\caption{Typing judgements in the MiniML type system.}
\label{fig:TypingJudgements}
\end{figure}

\subsubsection{Rules}
%\begin{figure}
\begin{align*}
&\Gamma \vdash true : bool \tag{T-True} \\
&\Gamma \vdash false : bool \tag{T-False} \\
&\Gamma \vdash num \; n : nat \tag{T-Num} \\ \\
\tag{T-Mono}
&\frac{\sigma \geq \tau \longspace id:\sigma \in \Gamma}{\Gamma \vdash id:\tau}\\ \\
\tag{T-App}
&\frac{\Gamma \vdash e_{1}:\tau_{2} \rightarrow \tau_{1} \longspace \Gamma \vdash e_{2}:\tau_{2}}
{\Gamma \vdash e_{1}e_{2}:\tau_{1}} \\ \\
\tag{BuildContext1}
& id:\sigma \rightarrow \emptyset, (id:\sigma) \\ \\
\tag{BuildContext2}
&\frac{p_{1}:\sigma_{1} \rightarrow \Gamma_{1} \longspace p_{2}:\sigma_{2}\rightarrow \Gamma_{2}}
{(p_{1},p_{2}):\sigma_{1}\times \sigma_{2} \rightarrow \Gamma_{1}\cup \Gamma_{2}} \\ \\
\tag{T-Fun}
&\frac{p:\tau_{2} \rightarrow \Gamma_{2} \longspace \Gamma_{2} \cup \Gamma_{1} \vdash e:\tau_{1}}
{\Gamma_{1} \vdash \lambda(p:\tau).e:\tau_{2} \rightarrow \tau_{1}} \\ \\
\tag{T-IfThenElse}
&\frac{\Gamma \vdash e_{1}:bool \longspace \Gamma \vdash e_{2}:\tau \longspace \Gamma \vdash e_{3} : \tau}
{\Gamma \vdash if \; e_{1} \; then \; e_{2} \; else \; e_{3} : \tau} \\ \\
%\tag{T-Pair}
%&\frac{\Gamma \vdash e_{1}:\tau_{1} \longspace \Gamma \vdash e_{2}:%\tau_{2}}
%{\Gamma \vdash (e_{1},e_{2}) : \tau_{1}\times\tau_{2}} \\ \\
%\tag{T-PairLeft}
%&\frac{\Gamma \vdash p:\tau_{1}\times\tau_{2}}
%{\Gamma \vdash \mathit{p.left} : \tau_{1}} \\
%\\
% \tag{T-PairRight}
%&\frac{\Gamma \vdash p:\tau_{1}\times\tau_{2}}
%{\Gamma \vdash \mathit{p.right} : \tau_{2}} \\
%\\
\tag{T-Let}
&\frac{\Gamma \vdash e_{2}:\tau_{2} \;\;\; \sigma=gen(\Gamma,\tau)\;\;\;p:\sigma\rightarrow \Gamma_{2} \;\;\; \Gamma \cup \Gamma_{2} \vdash e_{1}:\tau}
{\Gamma \vdash let\;p\;=\;e_{2}\;in\;e_{1}:\tau} 
%\\ \\
%\tag{T-Letrec}
%&\frac{\Gamma \vdash let\;p\;=\;\mathit{fix}\;(\lambda p.e_{2})\;in\%;e_{1}:\tau}
%{\Gamma \vdash letrec\;p\;=\;e_{2}\;in\;e_{1}:\tau} \\ \\
%\tag{T-Fix}
%&\frac{\Gamma \vdash e : \tau \rightarrow \tau}
%{\Gamma \vdash \mathit{fix\;e} : \tau} \\
%\displaybreak
\\
\tag{T-ModVarThis}
&\frac{\sigma \geq \tau \longspace this.id:\sigma \in \Gamma}
{\Gamma \vdash this.id : \tau} \\ 
\\
\tag{T-ModVarOther}
&\frac{
\Gamma \vdash M_{i}
\longspace id:\tau \in \Gamma[M_{i}].\Sigma}
{\Gamma \vdash \mathit{M_{i}.id} : \tau} \\
\\
%\tag{T-FunctorVar}
%&\frac{\overline{\Gamma \vdash M_{1..n}}
%\longspace
%\overline{\Sigma_{3} \succeq \Gamma[M_{1..n}].\Sigma}
%\longspace
%\Gamma \vdash F_{i}(\overline{M_{1..n}})
%\longspace
%id:\tau \in \Gamma[F_{i}].\Sigma_{1}}
%{\Gamma \vdash \mathit{F_{i}(\overline{M_{1..n}}).id}:\tau} \\
%\\
\displaybreak
\tag{T-Module}
&\frac{
\emptyset \vdash \Gamma[M_{i}].\overline{d}\rightarrow \Gamma' \longspace \Gamma' \vdash \Gamma[M_{i}].\Sigma_{i}}
{\Gamma \vdash M_{i}} \\
\\
%\tag{T-Functor}
%&\frac{
%\emptyset \vdash [\overline{M_{1..n} \mapsto M_{arg}}]\overline{d} \rightarrow \Gamma' \longspace \Gamma' \vdash \Gamma[F_{i}].\Sigma}
%{\Gamma \vdash F_{i}(\overline{M_{args}})}\\
\\
\tag{T-ModInterfaceField}
&\frac{(x:\tau) \in \Gamma \longspace \Gamma \vdash \Delta}
{\Gamma \vdash (x:\tau),\Delta}\\
\\
\tag{T-ModInterfaceModule}
&\frac{(M=\lbrace \Sigma_{2}, \overline{d} \rbrace^{M}) \in \Gamma
\longspace \Sigma_{1} \succeq \Sigma_{2} 
\longspace \Gamma \vdash \Delta}
{\Gamma \vdash (M:\Sigma_{1}),\Delta}\\
\\
\tag{T-ModBodyV}
&\frac{ (x:\tau),\Gamma \vdash \overline{d} \rightarrow \Gamma' \longspace \Gamma \vdash e:\tau}
{\Gamma \vdash (x=e:\tau),\overline{d} \rightarrow (x:\tau),\Gamma'} \\
\\
\tag{T-ModBodyM}
&\frac{\Gamma \vdash \lbrace\Sigma, \overline{d} \rbrace^{M_{i}} }
{\Gamma \vdash (\mathit{M_{i}=\overline{d}}:\Sigma),\overline{d} \rightarrow (M_{i}=\lbrace \Sigma,\overline{d} \rbrace),\Gamma'} \\
\\
\tag{T-EmptySet}
&\frac{\Gamma \vdash \Diamond}
{\Gamma \vdash \emptyset}
\end{align*}
%\end{figure}
\todo{Must specify $\succeq$ to mean the specialization of an interface}

\subsection{Operational semantics}
\begin{align*}
\text{Value }v ::=\;&\mathit{num\;n} \; | \; \mathit{true} \; | \; \mathit{false} \\
% &| (v,v) \\
&| \lambda p.e\\
\\
\text{Module Table } T\; ::= \;&\emptyset \\
&| \; (M_{i} \mapsto \lbrace \Sigma,\overline{d}\rbrace), T \\
%&| \; (F_{i} \mapsto \lbrace \Sigma, \overline{\Sigma_{n}}, \overline{d} \rbrace), T \\
&| \; (S_{i} \mapsto \Sigma), T\\
\\
\text{Evaluation } ::= T \vdash &e \rightarrow T \vdash e' \\
\end{align*}

The operational semantics defines a module table T, containing mappings from the signature-%, module and functor identifiers to their definition and and the evaluation relation. 
and module identifiers to their definition and and the evaluation relation. 

The module table T allows looking up the definition behind a certain identifier and accessing a certain part of it using projection. $T[M_{i}].\Sigma$ will give access to the $\Sigma$ in the definition of $M_{i}$. 

The evaluation relation allows the evaluation of an expression $e$ to a (simpler) expression $e'$, while potentially making a lookup in T.

\subsubsection{Rules}
\begin{align*}
\tag{E-IfTrue}
&T \vdash if \; true  \; then \; e_{1} \; else \; e_{2} \rightarrow T \vdash e_{1}\\
\tag{E-IfFalse}
&T \vdash if \; false \; then \; e_{1} \; else \; e_{2} \rightarrow T \vdash e_{2}\\ \\
\tag{E-IfThenElse}
&\frac{T \vdash e_{1} \rightarrow T \vdash e_{1}'}
{T \vdash if \; e_{1} \; then \; e_{2} \; else \; e_{3} \rightarrow T \vdash if \; e_{1}' \; then \; e_{2} \; else \; e_{3}}\\ \\
%\tag{E-PairLeft}
%&\frac{T \vdash e_{1} \rightarrow T \vdash e_{1}'}
%{T \vdash (e_{1},e_{2}) \rightarrow T \vdash (e_{1}',e_{2})} \\ \\
%\tag{E-PairRight}
%&\frac{T \vdash e_{2} \rightarrow T \vdash e_{2}'}
%{T \vdash (e_{1},e_{2}) \rightarrow T \vdash (e_{1},e_{2}')} \\ \\
\tag{E-Let}
&\frac{T \vdash e_{1}\rightarrow T \vdash e_{1}'}
{T \vdash let \; p \; = \; e_{1} \; in \; e_{2} \rightarrow T \vdash let \; p \; = \; e_{1}' \; in \; e_{2}}
\\ \\
\tag{E-LetV}
&T \vdash let \; id \; = \; v \; in \; e \rightarrow T \vdash [id \mapsto v]e \\ \\
%\tag{E-LetRec}
%& T \vdash letrec\;p=\;e_{1} \; in \; e_{2} \rightarrow T \vdash let \; p \; = %fix(\lambda p.e_{1}') \; in \; e_{2} \\ \\ 
%\tag{E-Fix}
%&\frac{T \vdash e\rightarrow T \vdash e'}
%{T \vdash fix(e) \rightarrow T \vdash fix(e')}\\ \\
%\tag{E-FixRec}
%&T \vdash fix(\lambda(p.e)) \rightarrow T \vdash [p \mapsto (fix %(\lambda(p.e))]e \\
\\
\tag{E-PatternMatch}
&T \vdash let \; (p_{1},p_{2}) \; = \; (e_{1},e_{2}) \; in \; e_{3} \rightarrow
let \; p_{1} \; = \; e_{1} \; in \;
(let \; p_{2}  \; = \; e_{2} \; in \; e_{3}) \\ \\
\tag{E-App1}
&\frac{T \vdash e_{1} \rightarrow T \vdash e_{1}'}
{T \vdash e_{1} e_{2} \rightarrow T \vdash e_{1}' e_{2}}\\ \\
\tag{E-App2}
&\frac{T \vdash e_{2} \rightarrow T \vdash e_{2}'}
{T \vdash v\;e_{2} \rightarrow T \vdash v\;e_{2}'}\\ \\
\tag{E-Lambda}
&T \vdash (\lambda x . e) \; v \rightarrow T \vdash [x \mapsto v]e \\ \\
\tag{E-MatchLambda}
&T \vdash (\lambda (p_{1},p_{2}) . e_{3}) \; (e_{1},e_{2}) \rightarrow T \vdash (\lambda p_{1}.(\lambda p_{2}.e_{3})\;e_{2})\; e_{1} \\
%\displaybreak
\\
\tag{E-ModVar}
&\frac{\longspace (x=e':\tau) \in T[M_{i}].\overline{d} \longspace e=[this.y\mapsto M.y]e'\;\forall (this.y \in e')}
{T \vdash M.x \rightarrow T \vdash e}\\
\\
%\tag{E-FunVar}
%&\frac{\longspace (x=e':\tau) \in T[F_{i}].\overline{d} \longspace %e=[M_{1..n} \mapsto M_{args}][this.y\mapsto F_{i}%(\overline{M_{args}}).y]e'\;\forall (this.y \in e')}
%{T \vdash F_{1}(\overline{M_{args}}).x \rightarrow T \vdash e}
\end{align*}
%\todo{How to express the substitution of all references to argument placeholder module names to the modules names given at execution}
%\todo{provide a desugar function}
%\end{flushleft}
\section{LLVM Intermediate Representation}
The LLVM Intermediate Representation is a language very reminiscent of assembly. 
\subsubsection{Syntax}
In \myref{fig}{fig:LLVMSyntax}, the reduced syntax of LLVM is given\todo{Formalize this citation into the correct style}\todo{Expand the syntax}.\footnote{Taken from "Formalizing the LLVM Intermediate
Representation for Verified Program
Transformations"}
\begin{figure}[!htb]
\begin{align*}
\begin{aligned}
\text{Modules }\mathit{mod} ::= &\overline{\mathit{prod}} \\
\text{Products }prod ::= & \mathit{global}\ \mathit{typ}\ \mathit{const}\ \mathit{align}\ | \mathit{define\ typ\ id(\overline{arg})\{\overline{b}\}}\\
&| \mathit{declare\ typ\ id(\overline{arg})} \\
\text{Types } \mathit{typ} ::= &\mathit{ isz\ |\ void\ |\ typ*\ |\ \left[sz \times typ\right]\ |\ \lbrace\ \overline{typ_{j}}^{j}\ \rbrace\ |\ typ\ \overline{typ_{j}}^{j}\ \rbrace\ | id}
\end{aligned}
\end{align*}
\label{fig:LLVMSyntax}
\caption{The reduced LLVM Syntax, taken from Jianzhou Zhao et al.}
\end{figure}

%\text{Types } \mathit{typ\ ::= }&\mathit{ isz | void | typ* | } 

%\end{align*}

\section{Formalized Compiler}
\newcommand{\compile}[1]{\left[\left[#1\right]\right]}
\newcommand{\makes}{& \rightarrow}
\begin{align*}
\begin{aligned}
\compile{\bar{S};\bar{M};e} \makes \compile{\bar{M}}^{\bar{S}};\compile{e}\\ 
\compile{\bar{M}}^{\bar{S}}\makes \compile{M_{i}:S_{i} = \bar{d}};\compile{\bar{M}}^{\bar{S}}\\
\compile{M_{i}:S_{i} = \bar{d}} \makes \compile{\bar{d}}^{S_{i}} \mathit{\ with\ } S_{i} \in \bar{S} \\
\compile{d:\bar{d}}^{S_{i}} \makes \compile{d}^{S_{i}};\compile{\bar{d}}^{S_{i}}
\end{aligned}
\end{align*}

\chapter{Advanced ML Concepts}

This chapter extends the capabilities of the subset of the ML language. \myref{sec}{sec:HOF} introduces \emph{higher-order functions} and discusses how they can be compiled securely. Afterwards, \myref{sec}{sec:Functors} explains \emph{functors} and their addition to the high-level language. This chapter continues by showing how the concepts learnt while adding higher-order functions can aid the low-level implementation of functors in \myref{sec}{sec:Functors}.
%The impact of these additions to the language is reviewed.

\section{Higher-Order Functions\label{sec:HOF}}

A \emph{higher-order function} is a function that allows other functions to be given as input or returns a function as output. \mbox{MiniML} by treats functions as first-class values, meaning that functions represent an entity that can be passed around as a parameter or return value and can be assigned to a variable.

\subsection{Lexical Scoping And Closures}
An example of a higher-order function is shown in \myref{lst}{code:LexicalScopingExample}. 
The function \lsttext{addCurried} takes an argument \lsttext{x} and as a result returns another function.
Therefore, \lsttext{addCurried} is a higher-order function.

Since \mbox{MiniML} uses what in literature is known as \emph{lexical scoping}, the function that addCurried returns is allowed access to the non-local or free variable \lsttext{x}, even though it is not defined within the local scope of the function, because its defined scope \emph{lexically surrounds} the definition of the function.

%Since \mbox{MiniML} uses lexical scoping, functions can be defined as shown in \myref{lst}{code:LexicalScopingExample}. The function \lsttext{addCurried} takes an argument \lsttext{x} and as a result returns another function. Therefore, it is a higher-order function. The function \lsttext{innerFunction} has access to the non-local or free variable \lsttext{x}, even though it is not defined in the local scope.

\begin{lstlisting}[frame=single, language=ML,caption=The use of lexical scoping calls for closures., label=code:LexicalScopingExample,numbers=left]
fun addCurried x = 
  let innerFunction y = x + y in innerFunction
\end{lstlisting}
\label{code:LexicalScopingExample}

This raises the need to add the concept of \emph{closures} to \mbox{MiniML}.
A closure consists of a simple function reference together with a referencing environment which contains all the free variables that are available due to the lexical scoping rules.
When a function is created using a call to \lsttext{addCurried} (and possibly saved in a variable to call it later on) this function must be able to access the variable \lsttext{x} that was given as a parameter to \lsttext{addCurried}.
The function entity created and possibly saved in a variable in other words must keep track of the non-local variables it has access to.
This list of non-local variables and their values is called the \emph{referencing environment}.

It is possible for these free variables to be complex data such as arrays or abstract data types, for example the Dictionary from \myref{lst}{code:DictionaryStructureExample}. 

The origin of free variables of the higher-order function could be trusted or untrusted code alike, just as the function can be defined in either trusted or untrusted code.
This allows for a case by case analysis of the four distinct combinations of pointer and variable(s).

\subsubsection{Secure Free Variables For A Secure Pointer}

In this case, the code that is executed when the closure is called runs within the \emph{SPM} itself.
The \emph{function pointer} and the \emph{referencing environment} are both in secure memory and are protected from any tampering by the low-level access control model and the checking performed upon compilation.

\subsubsection{Insecure Free Variables For A Secure Pointer}
If a closure is created with free variables stemming from untrusted code, the values of these free variables should be copied to the referencing environment inside the closure. 
This need arises because the low level code could otherwise change the value of the free variable at any time, as it would be located inside untrusted memory, even mid-execution of the higher-order function.
\myref{lst}{code:CopyFreeVariables} gives an example of two functions that are vulnerable to this kind of attack.

\begin{lstlisting}[frame=single, language=ML,caption=Changing free variables inside untrusted memory mid-execution can break contextual equivalence., label=code:CopyFreeVariables,numbers=left]
fun generateClosure1 freevar =
  let innerFunction x =
    (let b = freevar
    in x + callback 2 + b)
  in innerFunction

fun generateClosure2 freevar = 
  let innerFunction x = x + callback 2 + freevar
  in innerFunction
\end{lstlisting}
\label{code:CopyFreeVariables}

The two functions shown in \myref{lst}{code:CopyFreeVariables} are contextually equivalent in \mbox{MiniML}.
Their compiled versions however are not contextually equivalent unless the free variables from untrusted code are copied to the trusted memory.
If no copying of free variables occures, an attacker could set distinguish a module using \lsttext{generateClosure1} from one using \lsttext{generateClosure2} using the following attack:


\begin{attack}{Call-by-value Attack}
\begin{enumerate}
\item After calling the closure, the attacker forces execution to temporarily be passed back to the unsafe code.
This is achieved in \myref{lst}{code:CopyFreeVariables} by means of the callback function. 
Even when no callbacks are available this type of attack remains possible. For example, in a more powerful language providing a multithreaded environment, such an execution passing can be forced using a context switch.
\item The context uses this opportunity and the fact that \lsttext{freevar} is saved in unprotected memory to change the value of \lsttext{freevar}. This not possible in the high-level language, but the low-level language provides no guarantees whatsoever against modification of the unprotected memory.
\item If the implementation of \lsttext{generateClosure1} was used, then the result of the closure application depends on when exactly execution was temporarily switched to the attackers' context.
If this happened after copying the value of \lsttext{freevar} to \lsttext{b}, which is saved in protected memory, then the result of the closure will not reflect the change of value of \lsttext{freevar} by the attackers context.
If the execution switch happens before this copying of \lsttext{freevar} into protected memory, then the result will be computed using the changed value of \lsttext{freevar}.

In contrast, a version using  \lsttext{generateClosure2} never copies the value of \lsttext{freevar} into protected memory. 
Therefore the result of the closure will allways be computed using the changed value of \lsttext{freevar}.
\end{enumerate}
\end{attack}


The attack described above shows that it is possible to manipulate the low-level versions of the code of \myref{lst}{code:CopyFreeVariables} in such a way that the two different functions do not give the same result. 
Consequently, this means that the contextual equivalence of the compiled code is broken, whereas the high-level code is unaffected by the attack.
After all, the high-level language does not allow the memory location of the parameter that was passed to be changed which is a necessary access right to perform step two of the attack.

This problem is effectively mitigated by ensuring that upon \emph{application} of the closure every value is copied to the secure environment, conforming to a value-passing call semantic.

%Todo: Remark that this is necessary for complex data in regular function calling as well.

%Todo: what if the free-variable IS a reference. Then we must follow the reference chain all the way?! No, we follow high-level semantics, and Ref's make MiniML storage aware. If a Reference to storage is created by the attackers context, and this reference is passed as a parameter, it is okay for the attacker to change the value in the storage location, as long as the location remains the same. 

\subsubsection{Insecure Free Variables For An Insecure Pointer}

This combination entails no interaction between the attackers context and the \emph{SPM} beyond the regular means of function calling.
This means that it is not necessary to introduce security measures beyond those discussed in the previous chapters.
How closures and their values are represented is only important to the extent to which implementation for this case and the other cases might be shared by tackling the problem in a generic way.

\subsubsection{Secure Free Variables For An Insecure Pointer}

As stated in \myref{chap}{chap:ACompilationExample}, objects created by secure code should not leave the safety of secure memory provided by the low-level acces control model.
Instead, these values passed must be masked and represented in the insecure code by their masking index.
These same measures are necessary when working with closures.
As long as we obey these measures, and represent secure free variables in the referencing environment by their masking index, they are not susceptible to tampering, illegal disclosure or any other manipulation attacks.
The only way to interact with these secure free variables is by passing them as parameters to functions within the \emph{SPM}.
This shows that the added power of closures does not require any new security measures for this interaction between \emph{SPM} and the attackers context.


\subsection{Cross-boundary Passing Of A Secure Closure }
This section explores the security measures that must be taken when the closure itself, which is a first class value, is passed as an object across the boundary between \emph{SPM} and the attackers context.
If an \emph{SPM} would pass a closure generated inside its body to the untrusted code, the untrusted code could change the value of the function pointer and inspect or change the values saved in the referencing environment.

Each of these actions break contextual equivalence:
\begin{description}
\item[Change pointer value.] The pointer to the code might be changed to code that makes certain assumptions about the structure used to implement abstract data types.
This way, the context could discern between contextually equivalent SPMs in which the assumptions may or may not hold. \todo{provide vulnerability example}
\item[Inspect environment values.]
Assumptions about the way abstract data types are structured can be checked by inspecting the environment values. \todo{provide vulnerability example}
\item[Change environment values.] Changing values in the reference environment allows an attacker to discern between higher order functions which first copy their free variables and higher order functions that do not, as shown in \myref{lst}{code:CopyFreeVariables}.
\end{description}

As a result, the closure entity itself should not be passed across the boundary between the \emph{SPM} and the trusted code.
Instead, the closure should be masked, and its corresponding index in the masking map is passed to the untrusted code.
In order to later execute the closure, the \emph{SPM} should offer an \emph{closure-evaluation entry point}.
This entry point first takes a pointer to a closure in the masking map.
Then, because it is located within the \emph{SPM}, the entry point is able to jump to the function pointer specified by the closure and run the function code.

\subsubsection{The Closure-Evaluation Entry Point}

Because closures can be passed freely, it is possible for insecure code to obtain a closure value.
Of course this insecure code is allowed to make use of the closure, and execute the underlying function.
Execution of a closure is also called the \emph{evaluation} of the closure.
Application of a secure closure by the code in this context is not possible in a direct and straightforward way: the context is not capable of jumping to the code representing the closure because the code that corresponds to the closure might not be located at an entry point of the \emph{SPM} and because it has only knowledge of the masking index of the closure.

To allow insecure code to execute a closure, the \emph{SPM} offers one generic \emph{closure-evaluation entry point}. This entry point should:

\begin{enumerate}
\item Take a masked index as a parameter
\item Allow for an unspecified amount of other parameters to be passed as well, which will be relayed as parameters to the function represented by the closure.
\item Copy the parameters provided by the attackers context in order to prevent \emph{call-by-value attacks} as shown in \myref{lst}{code:CopyFreeVariables}.
\item Look up the masked index and retrieve the closure being referenced, i.e. the function pointer and the referencing environment containing the free variables.
\item Jump to the function pointer providing copies of any parameters it might require, as well as the referencing environment.
\item When execution of the closure is finished, the closure-evaluation entry point provides cleanup of the copied values and performs the tasks necessary for all entry points to the \emph{SPM} code such as register and flag emptying.
\end{enumerate}

The code that implements these different requirements and responsabilities is shown in \myref{lst}{llvm:EvalEntryPoint}.

\begin{lstlisting}[frame=single,numbers=left, language={[x86masm]Assembler}, caption=The generic closure-evaluation entry point.,
label=llvm:EvalEntryPoint]
\end{lstlisting}\todo{Todo: copy (cleaned up) code.}

\section{Functors\label{sec:Functors}}
\end{document}
